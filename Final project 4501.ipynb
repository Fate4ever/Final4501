{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c5a136-e872-4846-9965-9ddc5251a0b3",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an idea of a possible approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f675d4b-794e-407c-aac9-b85c4a3975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sqlalchemy.orm import declarative_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a21e842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: SQLAlchemy\n",
      "Version: 2.0.21\n",
      "Summary: Database Abstraction Library\n",
      "Home-page: https://www.sqlalchemy.org\n",
      "Author: Mike Bayer\n",
      "Author-email: mike_mp@zzzcomputing.com\n",
      "License: MIT\n",
      "Location: /Users/fate4ever/anaconda3/lib/python3.11/site-packages\n",
      "Requires: typing-extensions\n",
      "Required-by: GeoAlchemy2\n",
      "Requirement already satisfied: sqlalchemy in /Users/fate4ever/anaconda3/lib/python3.11/site-packages (2.0.21)\n",
      "Collecting sqlalchemy\n",
      "  Obtaining dependency information for sqlalchemy from https://files.pythonhosted.org/packages/c7/55/d1d2ad054fb7e9188681d56df40ed81c2c198314a805b180b0ec99019da1/SQLAlchemy-2.0.23-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.23-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/fate4ever/anaconda3/lib/python3.11/site-packages (from sqlalchemy) (4.7.1)\n",
      "Downloading SQLAlchemy-2.0.23-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.21\n",
      "    Uninstalling SQLAlchemy-2.0.21:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.21\n",
      "Successfully installed sqlalchemy-2.0.23\n"
     ]
    }
   ],
   "source": [
    "!pip show sqlalchemy\n",
    "!pip install --upgrade sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70a62277-51cf-48a2-81d2-9b2127088a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"UydgE9GUfZyuG9IpbKml1aKct\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"IE4501_Project_DB\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd67cca9-ec72-44e3-83b8-b65f1ed5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52476a07-9bf2-4b7a-8cb7-93648bb4d303",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b18f12-c0ce-4b9c-adc1-805703edc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url, force=False):\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    filename = DATA_DIR / url_path\n",
    "    \n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(..., f)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a48c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee245240-2fbb-45b8-9a92-4e2368f62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "     # Load the data using geopandas\n",
    "    gdf = gpd.read_file(ZIPCODE_DATA_FILE)\n",
    "    \n",
    "    print(gdf)\n",
    "\n",
    "    # Drop unnecessary columns. Here, you need to decide which columns are relevant\n",
    "    # For example, if you only need the zipcode and geometry, you can drop the rest\n",
    "    columns_to_keep = ['geometry']\n",
    "    gdf = gdf[columns_to_keep]\n",
    "\n",
    "    # Remove invalid data points\n",
    "    # This depends on what you define as invalid. As an example, you might want to remove rows with missing values\n",
    "    gdf = gdf.dropna()\n",
    "\n",
    "    # Normalize column names\n",
    "    # If you want to make column names lowercase for consistency\n",
    "    gdf.columns = [col.lower() for col in gdf.columns]\n",
    "\n",
    "    # Normalize data types if needed\n",
    "    # For example, ensuring ZIPCODE is a string, not a number\n",
    "    gdf['geometry'] = gdf['geometry'].astype(str)\n",
    "\n",
    "    # Additional cleaning steps can be added here depending on your specific requirements\n",
    "\n",
    "    return gdf\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c385d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              geometry\n",
      "0    POLYGON ((1038098.252 188138.380, 1038141.936 ...\n",
      "1    POLYGON ((1001613.713 186926.440, 1002314.243 ...\n",
      "2    POLYGON ((1011174.276 183696.338, 1011373.584 ...\n",
      "3    POLYGON ((995908.365 183617.613, 996522.848 18...\n",
      "4    POLYGON ((991997.113 176307.496, 992042.798 17...\n",
      "..                                                 ...\n",
      "258  POLYGON ((950767.507 172848.969, 950787.510 17...\n",
      "259  POLYGON ((1028453.995 167153.410, 1027813.010 ...\n",
      "260  POLYGON ((995877.318 203206.075, 995968.511 20...\n",
      "261  POLYGON ((997731.761 219560.922, 997641.948 21...\n",
      "262  POLYGON ((986038.661 213051.063, 986135.314 21...\n",
      "\n",
      "[263 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0h/g9zsw1191fl05wqh_8_l7p_w0000gn/T/ipykernel_30185/339113466.py:22: UserWarning: Geometry column does not contain geometry.\n",
      "  gdf['geometry'] = gdf['geometry'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((1038098.251871 188138.380007, 103814...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((1001613.712964 186926.439517, 100231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((1011174.275536 183696.33771, 1011373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((995908.365451 183617.612802, 996522....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((991997.113431 176307.49586, 992042.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>POLYGON ((950767.506586 172848.968656, 950787....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>POLYGON ((1028453.994913 167153.409838, 102781...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>POLYGON ((995877.318269 203206.074937, 995968....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>POLYGON ((997731.760754 219560.922148, 997641....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>POLYGON ((986038.661437 213051.063121, 986135....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              geometry\n",
       "0    POLYGON ((1038098.251871 188138.380007, 103814...\n",
       "1    POLYGON ((1001613.712964 186926.439517, 100231...\n",
       "2    POLYGON ((1011174.275536 183696.33771, 1011373...\n",
       "3    POLYGON ((995908.365451 183617.612802, 996522....\n",
       "4    POLYGON ((991997.113431 176307.49586, 992042.7...\n",
       "..                                                 ...\n",
       "258  POLYGON ((950767.506586 172848.968656, 950787....\n",
       "259  POLYGON ((1028453.994913 167153.409838, 102781...\n",
       "260  POLYGON ((995877.318269 203206.074937, 995968....\n",
       "261  POLYGON ((997731.760754 219560.922148, 997641....\n",
       "262  POLYGON ((986038.661437 213051.063121, 986135....\n",
       "\n",
       "[263 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_zipcodes(ZIPCODE_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed2a5a9-1027-4c41-bbb5-039c32ce7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    import requests\n",
    "\n",
    "# Your Application Token\n",
    "    app_token = 'UydgE9GUfZyuG9IpbKml1aKct'\n",
    "\n",
    "# API endpoints for 311 and tree data\n",
    "    api_endpoint_311 = 'https://data.cityofnewyork.us/resource/erm2-nwe9.json'\n",
    "\n",
    "\n",
    "# Headers for authentication\n",
    "    headers = {\n",
    "        'X-App-Token': app_token\n",
    "    }\n",
    "\n",
    "# Make a GET request to the 311 data endpoint\n",
    "    response_311 = requests.get(api_endpoint_311, headers=headers)\n",
    "    data_311 = response_311.json()\n",
    "\n",
    "# Assuming you have loaded data into DataFrame\n",
    "    df = pd.DataFrame(data_311)  # Example for 311 data\n",
    "\n",
    "# Removing unnecessary columns\n",
    "    columns_to_keep = ['created_date', 'incident_zip', 'latitude','longitude',':@computed_region_efsh_h5xi']  # replace with actual column names\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "# Remove invalid data points\n",
    "    #df = df[df[':@computed_region_efsh_h5xi'] != null] \n",
    "    df = df.dropna()# Replace with your criteria\n",
    "\n",
    "# Normalize column names\n",
    "    df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "# Convert data types\n",
    "    #df['date_column'] = pd.to_datetime(df['date_column'])\n",
    "   # df['numeric_column'] = pd.to_numeric(df['numeric_column'], errors='coerce')\n",
    "\n",
    "# For geospatial data\n",
    "   # gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "   # gdf.set_crs(\"EPSG:4326\", inplace=True)  # Replace with current SRID\n",
    "   # gdf.to_crs(\"EPSG:NEW_SRID\", inplace=True)  # Replace with desired SRID\n",
    "    \n",
    "    sampled_df = df.sample(n=10)  # Replace 100 with the number of samples you need\n",
    "    print(sampled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff42056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                created_date incident_zip            latitude  \\\n",
      "231  2023-11-30T23:57:42.000        11226   40.65099388458564   \n",
      "855  2023-11-30T22:14:35.000        10456   40.82569518319719   \n",
      "21   2023-12-01T00:54:01.000        10024   40.78270444876873   \n",
      "932  2023-11-30T22:03:10.000        11211  40.716254989335106   \n",
      "670  2023-11-30T22:41:32.000        10001   40.75066178373737   \n",
      "686  2023-11-30T22:38:11.000        11201   40.69340015431026   \n",
      "208  2023-12-01T00:03:42.000        10456  40.828265237460535   \n",
      "901  2023-11-30T22:07:02.000        11368  40.744033776595664   \n",
      "799  2023-11-30T22:22:18.000        11369   40.76415769024426   \n",
      "779  2023-11-30T22:25:00.000        11205    40.6924668113589   \n",
      "\n",
      "              longitude :@computed_region_efsh_h5xi  \n",
      "231  -73.96440523742638                       13510  \n",
      "855  -73.90661516095976                       10934  \n",
      "21   -73.97729446204836                       12421  \n",
      "932  -73.95301450423615                       17613  \n",
      "670  -74.00343234416158                       11722  \n",
      "686  -73.98891486387227                       16865  \n",
      "208  -73.91500549597097                       10934  \n",
      "901  -73.86738967489309                       14510  \n",
      "799   -73.8668803161328                       14511  \n",
      "779  -73.95476577524396                       17212  \n"
     ]
    }
   ],
   "source": [
    "download_and_clean_311_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c4b1bc-c841-4b87-8301-1dc2cafeccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    app_token = 'UydgE9GUfZyuG9IpbKml1aKct'\n",
    "    api_endpoint_tree = 'https://data.cityofnewyork.us/resource/5rq2-4hqu.geojson'\n",
    "    headers = {\n",
    "        'X-App-Token': app_token\n",
    "    }\n",
    "    response_tree = requests.get(api_endpoint_tree, headers=headers)\n",
    "    data_tree = response_tree.json()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d2cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_clean_tree_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747ff49f-a18b-4fc0-8da6-6834a10d11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data():\n",
    "   # Load the data using pandas, as we need to handle both non-spatial and spatial data\n",
    "    df = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "    print(df)\n",
    "\n",
    "    # Keep only the necessary columns\n",
    "    columns_to_keep = [\"RegionID\", \"SizeRank\", \"RegionName\", \"StateName\", \"City\", \"Metro\", \"CountyName\", \"2023-01-31\", \"2023-08-31\"]\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # Remove rows with missing values in any of the columns\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Normalize column names to lowercase\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "    # Normalize data types\n",
    "    # Assuming 'RegionID' and 'SizeRank' should be integers, and dates should be in datetime format\n",
    "    df['regionid'] = df['regionid'].astype(int)\n",
    "    df['sizerank'] = df['sizerank'].astype(int)\n",
    "\n",
    "\n",
    "    # Convert DataFrame to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df)\n",
    "\n",
    "    # Normalize SRID of any geometry if present\n",
    "    # Example: gdf.set_crs(epsg=YOUR_EPSG_CODE, inplace=True)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2232c998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RegionID  SizeRank  RegionName RegionType StateName State  \\\n",
      "0        91982         1       77494        zip        TX    TX   \n",
      "1        91940         3       77449        zip        TX    TX   \n",
      "2        91733         5       77084        zip        TX    TX   \n",
      "3        93144         6       79936        zip        TX    TX   \n",
      "4        62093         7       11385        zip        NY    NY   \n",
      "...        ...       ...         ...        ...       ...   ...   \n",
      "6717    418163     30158       89158        zip        NV    NV   \n",
      "6718     72017     30490       32461        zip        FL    FL   \n",
      "6719     58956     30490        2876        zip        RI    RI   \n",
      "6720     91179     30490       76005        zip        TX    TX   \n",
      "6721     61618     30490       10004        zip        NY    NY   \n",
      "\n",
      "                   City                                   Metro  \\\n",
      "0                  Katy    Houston-The Woodlands-Sugar Land, TX   \n",
      "1                  Katy    Houston-The Woodlands-Sugar Land, TX   \n",
      "2               Houston    Houston-The Woodlands-Sugar Land, TX   \n",
      "3               El Paso                             El Paso, TX   \n",
      "4              New York   New York-Newark-Jersey City, NY-NJ-PA   \n",
      "...                 ...                                     ...   \n",
      "6717          Las Vegas        Las Vegas-Henderson-Paradise, NV   \n",
      "6718  Panama City Beach  Crestview-Fort Walton Beach-Destin, FL   \n",
      "6719   North Smithfield               Providence-Warwick, RI-MA   \n",
      "6720          Arlington         Dallas-Fort Worth-Arlington, TX   \n",
      "6721           New York   New York-Newark-Jersey City, NY-NJ-PA   \n",
      "\n",
      "             CountyName   2015-01-31  ...   2022-12-31   2023-01-31  \\\n",
      "0      Fort Bend County  1606.206406  ...  1994.653463  2027.438438   \n",
      "1         Harris County  1257.814660  ...  1749.697900  1738.217986   \n",
      "2         Harris County          NaN  ...  1701.217520  1706.900064   \n",
      "3        El Paso County          NaN  ...  1419.480272  1458.063897   \n",
      "4         Queens County          NaN  ...  2935.808220  2895.699421   \n",
      "...                 ...          ...  ...          ...          ...   \n",
      "6717       Clark County          NaN  ...  3281.330738  3509.210744   \n",
      "6718      Walton County          NaN  ...          NaN          NaN   \n",
      "6719  Providence County          NaN  ...          NaN          NaN   \n",
      "6720     Tarrant County          NaN  ...  2148.224601  2169.143026   \n",
      "6721    New York County          NaN  ...  4006.972903  4000.923287   \n",
      "\n",
      "       2023-02-28   2023-03-31   2023-04-30   2023-05-31   2023-06-30  \\\n",
      "0     2042.237444  2049.325559  2016.531345  2023.438976  2031.558202   \n",
      "1     1747.305840  1758.407295  1758.891075  1762.980879  1771.751591   \n",
      "2     1706.067787  1723.722320  1735.484670  1752.132904  1756.990323   \n",
      "3     1471.726681  1466.734658  1456.175660  1462.478506  1466.267391   \n",
      "4     2873.209025  2881.906361  2913.546218  2963.964134  3005.735342   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "6717  3407.499896  3438.041504  3436.371804  3524.703410  3426.708975   \n",
      "6718          NaN          NaN          NaN          NaN  2583.675563   \n",
      "6719          NaN          NaN          NaN          NaN          NaN   \n",
      "6720  2179.393248  2226.624684  2369.532530  2374.713926  2414.638428   \n",
      "6721  4002.584212  4085.513015  4224.569373  4240.040733  4286.776061   \n",
      "\n",
      "       2023-07-31   2023-08-31   2023-09-30  \n",
      "0     2046.144009  2053.486247  2055.771355  \n",
      "1     1779.338402  1795.384582  1799.631140  \n",
      "2     1754.429516  1757.602011  1755.031490  \n",
      "3     1490.237063  1488.180414  1494.366097  \n",
      "4     3034.413822  3064.476503  3079.585783  \n",
      "...           ...          ...          ...  \n",
      "6717  3412.249969  3310.302151  3448.166667  \n",
      "6718  2590.977335  2639.938102  2702.500000  \n",
      "6719          NaN          NaN  2250.000000  \n",
      "6720  2389.749852  2383.185013  2313.944444  \n",
      "6721  4270.158740  4353.055657  4355.328283  \n",
      "\n",
      "[6722 rows x 114 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regionid</th>\n",
       "      <th>sizerank</th>\n",
       "      <th>regionname</th>\n",
       "      <th>statename</th>\n",
       "      <th>city</th>\n",
       "      <th>metro</th>\n",
       "      <th>countyname</th>\n",
       "      <th>2023-01-31</th>\n",
       "      <th>2023-08-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91982</td>\n",
       "      <td>1</td>\n",
       "      <td>77494</td>\n",
       "      <td>TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Fort Bend County</td>\n",
       "      <td>2027.438438</td>\n",
       "      <td>2053.486247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91940</td>\n",
       "      <td>3</td>\n",
       "      <td>77449</td>\n",
       "      <td>TX</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>1738.217986</td>\n",
       "      <td>1795.384582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91733</td>\n",
       "      <td>5</td>\n",
       "      <td>77084</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>Harris County</td>\n",
       "      <td>1706.900064</td>\n",
       "      <td>1757.602011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93144</td>\n",
       "      <td>6</td>\n",
       "      <td>79936</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso, TX</td>\n",
       "      <td>El Paso County</td>\n",
       "      <td>1458.063897</td>\n",
       "      <td>1488.180414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62093</td>\n",
       "      <td>7</td>\n",
       "      <td>11385</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>2895.699421</td>\n",
       "      <td>3064.476503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>66130</td>\n",
       "      <td>23188</td>\n",
       "      <td>20006</td>\n",
       "      <td>DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>1996.361061</td>\n",
       "      <td>2133.344583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6716</th>\n",
       "      <td>60648</td>\n",
       "      <td>27708</td>\n",
       "      <td>7311</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>Hudson County</td>\n",
       "      <td>3762.753868</td>\n",
       "      <td>3950.327047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>418163</td>\n",
       "      <td>30158</td>\n",
       "      <td>89158</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Las Vegas-Henderson-Paradise, NV</td>\n",
       "      <td>Clark County</td>\n",
       "      <td>3509.210744</td>\n",
       "      <td>3310.302151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6720</th>\n",
       "      <td>91179</td>\n",
       "      <td>30490</td>\n",
       "      <td>76005</td>\n",
       "      <td>TX</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>Tarrant County</td>\n",
       "      <td>2169.143026</td>\n",
       "      <td>2383.185013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>61618</td>\n",
       "      <td>30490</td>\n",
       "      <td>10004</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>New York County</td>\n",
       "      <td>4000.923287</td>\n",
       "      <td>4353.055657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4771 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      regionid  sizerank  regionname statename         city  \\\n",
       "0        91982         1       77494        TX         Katy   \n",
       "1        91940         3       77449        TX         Katy   \n",
       "2        91733         5       77084        TX      Houston   \n",
       "3        93144         6       79936        TX      El Paso   \n",
       "4        62093         7       11385        NY     New York   \n",
       "...        ...       ...         ...       ...          ...   \n",
       "6709     66130     23188       20006        DC   Washington   \n",
       "6716     60648     27708        7311        NJ  Jersey City   \n",
       "6717    418163     30158       89158        NV    Las Vegas   \n",
       "6720     91179     30490       76005        TX    Arlington   \n",
       "6721     61618     30490       10004        NY     New York   \n",
       "\n",
       "                                             metro            countyname  \\\n",
       "0             Houston-The Woodlands-Sugar Land, TX      Fort Bend County   \n",
       "1             Houston-The Woodlands-Sugar Land, TX         Harris County   \n",
       "2             Houston-The Woodlands-Sugar Land, TX         Harris County   \n",
       "3                                      El Paso, TX        El Paso County   \n",
       "4            New York-Newark-Jersey City, NY-NJ-PA         Queens County   \n",
       "...                                            ...                   ...   \n",
       "6709  Washington-Arlington-Alexandria, DC-VA-MD-WV  District of Columbia   \n",
       "6716         New York-Newark-Jersey City, NY-NJ-PA         Hudson County   \n",
       "6717              Las Vegas-Henderson-Paradise, NV          Clark County   \n",
       "6720               Dallas-Fort Worth-Arlington, TX        Tarrant County   \n",
       "6721         New York-Newark-Jersey City, NY-NJ-PA       New York County   \n",
       "\n",
       "       2023-01-31   2023-08-31  \n",
       "0     2027.438438  2053.486247  \n",
       "1     1738.217986  1795.384582  \n",
       "2     1706.900064  1757.602011  \n",
       "3     1458.063897  1488.180414  \n",
       "4     2895.699421  3064.476503  \n",
       "...           ...          ...  \n",
       "6709  1996.361061  2133.344583  \n",
       "6716  3762.753868  3950.327047  \n",
       "6717  3509.210744  3310.302151  \n",
       "6720  2169.143026  2383.185013  \n",
       "6721  4000.923287  4353.055657  \n",
       "\n",
       "[4771 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "345ebc2c-14f1-490c-9857-11f1e332e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2768bc8-4130-4298-be28-13d4b250a666",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Created Date', 'Incident Zip', 'Latitude', 'Longitude', 'Zip Codes'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data \u001b[38;5;241m=\u001b[39m load_all_data()\n",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m, in \u001b[0;36mload_all_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_all_data\u001b[39m():\n\u001b[1;32m      2\u001b[0m     geodf_zipcode_data \u001b[38;5;241m=\u001b[39m load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n\u001b[0;32m----> 3\u001b[0m     geodf_311_data \u001b[38;5;241m=\u001b[39m download_and_clean_311_data()\n\u001b[1;32m      4\u001b[0m     geodf_tree_data \u001b[38;5;241m=\u001b[39m download_and_clean_tree_data()\n\u001b[1;32m      5\u001b[0m     df_zillow_data \u001b[38;5;241m=\u001b[39m load_and_clean_zillow_data()\n",
      "Cell \u001b[0;32mIn[46], line 25\u001b[0m, in \u001b[0;36mdownload_and_clean_311_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Removing unnecessary columns\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     columns_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncident Zip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZip Codes\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# replace with actual column names\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[columns_to_keep]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Remove invalid data points\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#df = df[df['column_name'] != 'invalid_value']  # Replace with your criteria\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Normalize column names\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [col\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[0;32m~/python/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/python/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/python/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Created Date', 'Incident Zip', 'Latitude', 'Longitude', 'Zip Codes'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad8bbc-bf91-457e-97db-a945fabeee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68f4be-f365-46c1-91a1-ab75deb75ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a803b68-2f07-44b8-8b24-d4f16c9e03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14705df9-ea77-4d57-ac8e-1845f80a216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006cd2-3a00-4660-8d2a-a660b9bfd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f880ef-c5fc-4159-8174-21ccd44f492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59724f74-5f1e-435c-b843-f381a875dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ae5d9-9768-4590-a2f2-dd63b07dd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685942c-26dc-40db-84c2-a71aa3340806",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f349fbdd-67d0-40a4-97a0-d9b8c8ec8013",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (675149776.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    #raise NotImplementedError()\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def setup_new_postgis_database(username, db_name):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0deed27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createdb: error: database creation failed: ERROR:  database \"IE4501_Project_DB\" already exists\n"
     ]
    }
   ],
   "source": [
    "!createdb IE4501_Project_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc62a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psql: error: schema.sql: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!psql -U postgres -d IE4501_Project_DB -f schema.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64c6a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  extension \"postgis\" already exists\n"
     ]
    }
   ],
   "source": [
    "!psql --dbname IE4501_Project_DB -c 'CREATE EXTENSION postgis;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e72b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "590ed80d-7b60-484f-a123-23b673b0f440",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'setup_new_postgis_database' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fate4ever/Documents/GitHub/Final4501/Final project 4501.ipynb 单元格 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fate4ever/Documents/GitHub/Final4501/Final%20project%204501.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m setup_new_postgis_database(DB_USER, DB_NAME)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'setup_new_postgis_database' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "527a251c-f337-4b24-bb41-96ee4621a9bd",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "\n",
    "These are just a couple of options to creating your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d72390-3c2d-4856-82c0-3284e8ccb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac07405-dc2b-47af-9dad-6a9b94d2b34c",
   "metadata": {},
   "source": [
    "#### Option 1: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d0cc6-74b3-4d35-a454-57f647c9f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the SQL statements to create your 4 tables\n",
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d86f6-ff6e-4bb8-8fa2-df0d4282e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eacd37-4fd7-4768-b689-88b07d5c234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using SQL (as opposed to SQLAlchemy), execute the schema files to create tables\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a2d89-b276-4d44-a0ef-3631eb686e84",
   "metadata": {},
   "source": [
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c42e1-4ad4-4c43-a2ba-1dbcac1de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class Tree(Base):\n",
    "    __tablename__ = \"trees\"\n",
    "\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a9c3d-e6d6-4e01-8247-e9d465381ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88a50c-9528-4a5c-9a52-b96781ee8985",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "These are just a couple of options to write data to your tables; you can use one or the other, a different method, or a combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66af67-afb8-4f0d-bb57-552972f8e4b8",
   "metadata": {},
   "source": [
    "#### Option 1: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e37800-cd95-44b5-9c21-eb7ac2b2e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(tablename_to_dataframe):\n",
    "    # write INSERT statements or use pandas/geopandas to write SQL\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f042f5-8270-477d-929a-872f7d9a0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename_to_dataframe = {\n",
    "    \"zipcodes\": geodf_zipcode_data,\n",
    "    \"complaints\": geodf_311_data,\n",
    "    \"trees\": geodf_tree_data,\n",
    "    \"rents\": df_zillow_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d052c50-1e43-4356-bcac-4f5abc7e714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(tablename_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4708cb4-d034-43b6-955b-a21d0eab74d4",
   "metadata": {},
   "source": [
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ddbad-3b11-47a2-9245-935f482fa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b21c6-59d9-4bae-8c33-ab4b49ff2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in geodf_tree_data.iterrows():\n",
    "    tree = Tree(...)\n",
    "    session.add(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4bfb9-4fbc-45fe-8a98-a760a22234f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63b553-0c64-4da8-9fc7-41555d89d853",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7e12b-e251-4f08-8dc5-601db30c2089",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce8548-4aba-4bf9-992c-dedd0f249db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605e6f3-ec42-4a8b-833c-5138c14b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"FILL_ME_IN\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "FILL_ME_IN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce044adf-ecdf-4237-9b20-b7cdaaab0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b2c3d-8961-4c7e-8eb1-fc973d0ab9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75223ce5-6ab5-4613-b6af-fa8e33bcc7d5",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fcfed-ddbb-4908-a60e-ed7cbc6d5b00",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e2cde-e43b-407b-ab93-ff85a2dba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80755f-d1e1-4e53-8ef8-f5295c59a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query your database for the data needed.\n",
    "    # You can put the data queried into a pandas/geopandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2632a-b516-4a6e-8b67-97116ab6fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
